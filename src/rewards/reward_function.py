"""
Reward Function for Denial Prompting RL

Simplified reward for MVP:
1. Correctness: Does the code pass test cases? (0 to 1.0)
2. Denial Penalty: Did the model use denied techniques? (-0.5 per violation)

Total Reward = Correctness - (num_violations × penalty_weight)

This forces the model to generate correct code while avoiding denied techniques,
naturally encouraging exploration of diverse solutions.
"""

from typing import Dict, Any, List, Tuple, Optional

# Handle both package and standalone imports
try:
    from .code_executor import SafeCodeExecutor
    from .technique_detector import TechniqueDetector
except ImportError:
    from code_executor import SafeCodeExecutor
    from technique_detector import TechniqueDetector


class RewardFunction:
    """
    Simplified reward function for denial prompting RL training.

    Reward = Correctness - (num_violations × denial_penalty_weight)

    Args:
        correctness_weight: Weight for correctness component (default: 1.0)
        denial_penalty_weight: Penalty per violation (default: 0.5)
        timeout: Code execution timeout in seconds (default: 5)
    """

    def __init__(
        self,
        correctness_weight: float = 1.0,
        denial_penalty_weight: float = 0.5,
        timeout: int = 5,
    ):
        """Initialize reward function with weights."""
        self.correctness_weight = correctness_weight
        self.denial_penalty_weight = denial_penalty_weight

        self.executor = SafeCodeExecutor(timeout=timeout)
        self.detector = TechniqueDetector()

    def compute_reward(
        self,
        generated_code: str,
        test_cases: List[Tuple[Any, Any]],
        denied_techniques: List[str],
        metadata: Optional[Dict[str, Any]] = None,
    ) -> Dict[str, Any]:
        """
        Compute total reward for generated code.

        Simplified reward: Correctness - Denial_Penalty

        Args:
            generated_code: The code generated by the model
            test_cases: List of (input, expected_output) tuples
            denied_techniques: List of techniques that should not be used
            metadata: Optional additional metadata (problem_id, etc.)

        Returns:
            Dictionary containing:
            {
                'total_reward': float,                # Final reward value
                'correctness_score': float,           # 0 to 1.0 (supports partial credit)
                'denial_penalty': float,              # 0 to -penalty_weight * num_violations
                'num_violations': int,                # Number of denied techniques used
                'execution_result': Dict,             # Raw execution result
                'violation_result': Dict,             # Raw violation check result
                'success': bool,                      # True if all tests passed
            }
        """
        metadata = metadata or {}

        # Initialize result
        result = {
            'total_reward': 0.0,
            'correctness_score': 0.0,
            'denial_penalty': 0.0,
            'num_violations': 0,
            'execution_result': {},
            'violation_result': {},
            'success': False,
        }

        # 1. Correctness Score (most important)
        execution_result = self.executor.execute(
            generated_code,
            test_cases,
            function_name="solve"  # NeoCoder uses 'solve' as function name
        )

        result['execution_result'] = execution_result

        if execution_result['success']:
            correctness_score = self.correctness_weight
            result['success'] = True
        else:
            # Partial credit for passing some tests
            if execution_result['total'] > 0:
                pass_rate = execution_result['num_passed'] / execution_result['total']
                correctness_score = self.correctness_weight * pass_rate
            else:
                correctness_score = 0.0

        result['correctness_score'] = correctness_score

        # 2. Denial Penalty (enforce constraints)
        violation_result = self.detector.check_violations(
            generated_code,
            denied_techniques
        )

        result['violation_result'] = violation_result

        if not violation_result['compliant']:
            # Penalty per violation
            num_violations = violation_result['num_violations']
            denial_penalty = -self.denial_penalty_weight * num_violations
        else:
            denial_penalty = 0.0

        result['denial_penalty'] = denial_penalty
        result['num_violations'] = violation_result['num_violations']

        # Compute total reward (simplified)
        total_reward = correctness_score + denial_penalty

        result['total_reward'] = total_reward

        return result

    def compute_batch_rewards(
        self,
        batch: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """
        Compute rewards for a batch of problems.

        Args:
            batch: List of dictionaries, each containing:
                - 'generated_code': str
                - 'test_cases': List[Tuple]
                - 'denied_techniques': List[str]
                - 'metadata': Optional[Dict]

        Returns:
            List of reward result dictionaries
        """
        results = []

        for item in batch:
            result = self.compute_reward(
                generated_code=item['generated_code'],
                test_cases=item['test_cases'],
                denied_techniques=item.get('denied_techniques', []),
                metadata=item.get('metadata', {}),
            )

            results.append(result)

        return results


if __name__ == "__main__":
    # Test the simplified reward function
    print("="*80)
    print("Testing Simplified Reward Function")
    print("="*80)

    reward_fn = RewardFunction(
        correctness_weight=1.0,
        denial_penalty_weight=0.5,
    )

    # Test 1: Correct code, no violations
    print("\n--- Test 1: Correct code, no violations ---")
    code1 = """
def solve(nums):
    '''Sum all numbers using list comprehension'''
    return sum([x for x in nums])
"""
    test_cases1 = [([1, 2, 3], 6), ([0], 0), ([-1, 1], 0)]
    denied1 = ['for loop', 'while loop']

    result1 = reward_fn.compute_reward(code1, test_cases1, denied1)
    print(f"Total reward: {result1['total_reward']:.3f}")
    print(f"  Correctness: {result1['correctness_score']:.3f}")
    print(f"  Denial penalty: {result1['denial_penalty']:.3f}")
    print(f"  Num violations: {result1['num_violations']}")
    print(f"Success: {result1['success']}")

    # Test 2: Correct code, but with violation
    print("\n--- Test 2: Correct code WITH violation (uses for loop) ---")
    code2 = """
def solve(nums):
    result = 0
    for num in nums:
        result += num
    return result
"""
    result2 = reward_fn.compute_reward(code2, test_cases1, denied1)
    print(f"Total reward: {result2['total_reward']:.3f}")
    print(f"  Correctness: {result2['correctness_score']:.3f}")
    print(f"  Denial penalty: {result2['denial_penalty']:.3f}")
    print(f"  Num violations: {result2['num_violations']}")
    print(f"Success: {result2['success']}")
    print(f"Violations: {result2['violation_result']['violations']}")

    # Test 3: Incorrect code
    print("\n--- Test 3: Incorrect code ---")
    code3 = """
def solve(nums):
    return 42  # Wrong answer
"""
    result3 = reward_fn.compute_reward(code3, test_cases1, denied1)
    print(f"Total reward: {result3['total_reward']:.3f}")
    print(f"  Correctness: {result3['correctness_score']:.3f}")
    print(f"  Denial penalty: {result3['denial_penalty']:.3f}")
    print(f"Success: {result3['success']}")

    # Test 4: Code with syntax error
    print("\n--- Test 4: Code with syntax error ---")
    code4 = """
def solve(nums)  # Missing colon
    return sum(nums)
"""
    result4 = reward_fn.compute_reward(code4, test_cases1, denied1)
    print(f"Total reward: {result4['total_reward']:.3f}")
    print(f"  Correctness: {result4['correctness_score']:.3f}")
    print(f"  Denial penalty: {result4['denial_penalty']:.3f}")
    print(f"Error: {result4['execution_result']['error']}")

    # Test 5: Batch processing
    print("\n--- Test 5: Batch processing ---")
    batch = [
        {
            'generated_code': code1,
            'test_cases': test_cases1,
            'denied_techniques': denied1,
        },
        {
            'generated_code': code2,
            'test_cases': test_cases1,
            'denied_techniques': denied1,
        },
    ]

    batch_results = reward_fn.compute_batch_rewards(batch)
    print(f"Batch size: {len(batch_results)}")
    for i, result in enumerate(batch_results):
        print(f"  Sample {i+1}: reward={result['total_reward']:.3f}, violations={len(result['violation_result']['violations'])}")

    print("\n" + "="*80)
    print("Tests completed")
    print("="*80)
